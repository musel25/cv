\begin{rubric}{Compétences}
\noentry{~}

\entry*[Entraînement LLM]
PyTorch; HF Transformers/PEFT/TRL; tokenizers (SentencePiece/Tiktoken); SFT, LoRA/QLoRA, DPO; configs Hydra; HF Datasets (streaming);
suivi d’expériences (W\&B/MLflow/Comet).

\entry*[RAG et données]
Qdrant/FAISS (HNSW); découpage (récursif/sémantique); retrieveurs (self-querying/hybride) + rerankers (bge-reranker/Cohere); décontamination/PII; snapshots CDC; Pydantic; MongoDB+ODM; orchestration ZenML; crawling Selenium/Playwright.

\entry*[MLOps]
vLLM, TGI, llama.cpp (GGUF); quantification (GPTQ/EXL2), cache KV, batching continu, décodage spéculatif; FastAPI; AWS SageMaker (HF DLC); Docker/Kubernetes; GitHub Actions (CI/CD/CT); monitoring/garde-fous (Opik, OpenTelemetry); PyTorch Profiler; tests A/B.

\entry*[Évaluation]
lm-evaluation-harness; Ragas/ARES; prompts/semences déterministes; contrôles de contamination; métriques RAG et analyse d’erreurs.

\end{rubric}

